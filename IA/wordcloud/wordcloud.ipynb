{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install goose3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from goose3 import Goose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rafael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando um objeto da classe Goose\n",
    "# g é um objeto e Goose() - Construtor\n",
    "g = Goose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar uma url\n",
    "url = \"https://www.scielo.br/j/ea/a/c4sqqrthGMS3ngdBhGWtKhh\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo\n",
    "artigo =  g.extract(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Inteligência Artificial e sociedade: avanços e riscos'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analisando o título\n",
    "artigo.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'www.scielo.br'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artigo.domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta_descrition\n",
    "artigo.meta_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'utf-8'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# meta_encoding\n",
    "artigo.meta_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'goose3.article.Article'>\n"
     ]
    }
   ],
   "source": [
    "# Qual o tipo do objeto artigo\n",
    "print(type(artigo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data de publicação\n",
    "artigo.publish_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artigo.links    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Este artigo tem como objetivo prover informações para que o leitor comum possa melhor entender os principais aspectos da IA, em que ela difere da computação convencional e como ela pode ser inserida nos processos organizacionais da sociedade humana. Além disso, busca evidenciar os grandes avanços e potenciais riscos que essa tecnologia, tal como qualquer outra, pode provocar caso os atores envolvidos na sua produção, utilização e regulação não criem um espaço de discussão adequado destas questões.\\n\\nA inteligência artificial (IA), surgida na década de 1950, tem sua origem praticamente confundida com a própria origem do computador. Mais precisamente, no verão de 1956, ocorreu a Darthmouth College Conference, que é considerada o marco inicial da IA. Os pesquisadores reconhecidos como pais da área, como John MacCarthy, Marvin Minsky, Alan Newell e Herbert Simon, entre outros, participaram desse evento e tiveram trajetórias científicas que estabeleceram marcos nesse fascinante domínio da Computação.\\n\\nComo o nome mesmo insinua, a área sempre foi cercada de enormes expectativas, e em inúmeras vezes essas não foram completamente atingidas. Desse modo, a oscilação de humor em relação à área assemelha-se a uma curva senoidal, havendo períodos de grande entusiasmo e grande financiamento (como ocorre agora) seguidos por outros de decepção e recursos escassos. Estes últimos são conhecidos como AI Winter (Inverno da IA), como foram por exemplo os períodos entre 1975/1980 e 1987/1993.\\n\\nAtualmente, atravessamos novamente um período de euforia sobre os possíveis benefícios que a IA pode prover. Tal otimismo se justifica por uma conjunção de três fatores fundamentais: (i) o custo de processamento e de memória nunca foi tão barato; (ii) o surgimento de novos paradigmas, como as redes neurais profundas, possibilitados pelo primeiro fator e produzindo inegáveis avanços científicos; e (iii) uma quantidade de dados gigantesca disponível na internet em razão do grande uso de recursos tais como redes e mídias sociais. Tal entusiasmo, entretanto, vem sido acompanhado por uma série de temores, alguns dos quais fundados.\\n\\nO objetivo deste artigo é prover informações para que o leitor comum possa melhor entender os principais aspectos da IA, em que ela difere da computação convencional e como ela pode ser inserida nos processos organizacionais da sociedade humana. Além disso, busca evidenciar os grandes avanços e potenciais riscos que essa tecnologia, tal como qualquer outra, pode provocar caso os atores envolvidos na produção, utilização e regulação de seu uso não criem um espaço de discussão adequado destas questões.\\n\\nO que vem a ser IA?\\n\\nSempre que ocorre um entusiasmo com os resultados de uma tecnologia, existe uma tendência da mídia em fornecer definições e explicações, por vezes não muito precisas, dos seus principais aspectos. Isso é, certamente, o que ocorre com a IA nos dias de hoje.\\n\\nEm primeiro lugar, cabe ressaltar que não existe uma definição acadêmica, propriamente dita, do que vem a ser IA. Trata-se certamente de um ramo da ciência/engenharia da computação, e portanto visa desenvolver sistemas computacionais que solucionam problemas. Para tal, utiliza um número diverso de técnicas e modelos, dependendo dos problemas abordados. Portanto, é inadequado utilizar-se expressões como “a IA da empresa X”; mais adequado (porém com menos apelo) seria dizer “um sistema da empresa X que utiliza técnicas de IA”.\\n\\nAo invés de tentar fornecer uma definição de IA, mais adequado seria tentar caracterizar quais são os objetivos da área. Uma das primeiras tentativas desta abordagem, proposta em Rich e Knight (1991RICH, E.; KNIGHT, K. Artificial intelligence. 2.ed. s.l.: McGraw-Hill, 1991.), é a seguinte: o objetivo da IA é desenvolver sistemas para realizar tarefas que, no momento: (i) são mais bem realizadas por seres humanos que por máquinas, ou (ii) não possuem solução algorítmica viável pela computação convencional.\\n\\nPara entender melhor essa definição, necessita-se esclarecer o que vem a ser um algoritmo, palavra que também é bastante citada na mídia, às vezes de modo não muito preciso. Um algoritmo nada mais é do que uma sequência finita de ações que resolve um certo problema. Uma receita culinária, como a de um risoto, é um algoritmo. Assim, um algoritmo pode resolver problemas de tipos bastante diferentes: cálculo estrutural (projeto de uma ponte), processamento de dados (geração de uma folha de pagamentos) ou planejamento (definição de um pacote de turismo).\\n\\nQual a principal diferença entre esses problemas? Basicamente, certos problemas têm soluções exatas, como o projeto da ponte, o processamento da folha de pagamentos e a receita do risoto. Solução exata, nesse caso, significa que se os passos definidos no algoritmo forem executados exatamente na ordem definida, ter-se-á ao final uma ponte que resistirá às intempéries, uma folha de pagamentos sem futuros problemas com o fisco e um delicioso risoto à moda italiana.\\n\\nPor outro lado, problemas como a definição do pacote de turismo não têm uma solução exata, ou uma única solução. Outros exemplos similares são produção de diagnósticos (médicos, legais), geração automática de diálogos, reconhecimento de imagens etc. No caso do pacote de turismo, como garantir que é o melhor a ser adquirido? Deve-se escolher primeiro o voo ou o hotel? Quais datas teriam um custo menor? Existe disponibilidade nessas datas para todos os recursos desejados (hotéis, voos, passeios), e em caso positivo as férias podem ser marcadas nesse período?\\n\\nUma possível abordagem para solucionar tais problemas seria tentar gerar as possíveis soluções até que se obtenha a primeira delas, ou até que se encontre a melhor delas, caso existam várias soluções. Tal abordagem, apesar de teoricamente plausível, quase sempre é inviável na prática: a quantidade de possíveis soluções geradas é muito grande, e mesmo com um computador muito potente levaria muito tempo para obtê-las. Por exemplo, um problema de definição de rotas entre cidades poderia levar centenas de dias de processamento!\\n\\nAssim, tais problemas são usualmente mais bem solucionados por seres humanos, e na maioria dos casos de interesse não possuem solução algorítmica viável (em tempo de processamento) pela computação convencional.\\n\\nUma pergunta que se coloca então é a seguinte: Como nós, humanos, solucionamos esses problemas? Uma possível resposta é que utilizamos, de modo inato, um mecanismo de busca e poda: (i) geramos soluções candidatas ... mas quase nunca todas elas! (ii) escolhemos a melhor solução... de acordo com certo critério! e (iii) eventualmente, analisamos a posteriori o efeito das escolhas feitas... e as alteramos para o futuro i.e., aprendemos!\\n\\nAssim, o domínio de IA se caracteriza por ser uma coleção de modelos, técnicas e tecnologias (busca, raciocínio e representação de conhecimento, mecanismos de decisão, percepção, planejamento, processamento de linguagem natural, tratamento de incertezas, aprendizado de máquina) que, isoladamente ou agrupadas, resolvem problemas de tal natureza. Para tal, podem utilizar paradigmas distintos, sendo os principais os paradigmas simbólico, conexionista, evolutivo e probabilístico.\\n\\nSegundo o paradigma simbólico, deve-se inicialmente identificar o conhecimento do domínio (modelo do problema), para então representá-lo utilizando uma linguagem formal de representação e implementar um mecanismo de inferência para utilizar esse conhecimento.\\n\\nJá no paradigma conexionista, a linguagem é uma rede de elementos simples, inspirada no funcionamento do cérebro, onde neurônios artificiais, conectados em rede, são capazes de aprender e de generalizar a partir de exemplos. O raciocínio consiste em aprender diretamente a função entrada-saída. Matematicamente, trata-se de uma técnica de aproximação de funções por regressão não linear.\\n\\nO paradigma evolutivo, por sua vez, utiliza um método probabilístico de busca de soluções de problemas (otimização), onde soluções são representadas como indivíduos, aos quais se aplicam técnicas “inspiradas” na teoria da evolução como hereditariedade, mutação, seleção natural e recombinação (ou crossing over), para selecionar para as gerações seguintes os indivíduos mais adaptados, i.e., os que maximizam uma função objetivo (ou fitness function).\\n\\nFinalmente, o paradigma probabilístico utiliza modelos para representar o conceito estatístico de independência condicional, a partir de relacionamentos causais no domínio. A inferência consiste em calcular a distribuição condicional de probabilidades dessa distribuição, e em alguns casos particulares de topologia, existem algoritmos bastante eficientes.\\n\\nUma contribuição muito importante foi o surgimento do conceito de agente inteligente (Russell; Norvig, 2010RUSSELL, S. J.; NORVIG, P. Artificial Intelligence - A Modern Approach, Third International Edition. s.l.: Pearson Education, 2010.), proposto em 1995, que se tornou um paradigma integrador da área. Esse paradigma gerou uma nova área de pesquisa, denominada agentes autônomos e sistemas multiagentes, dedicada a investigar como as acima mencionadas técnicas de IA poderiam ser integradas de modo mais eficaz e efetivo em um único agente e também como um conjunto destes agentes poderia interagir de forma coordenada e cooperativa, visando resolver um problema quando nenhum deles de forma isolada poderia fazê-lo. Um conjunto de veículos autônomos seria um exemplo de um sistema multiagentes: não basta que cada um decida o melhor roteiro para atingir a meta de seu passageiro, mas é necessário que os veículos cooperem e se coordenem, para não causarem acidentes, como usualmente ocorre com condutores humanos.\\n\\nNessa nova e fascinante área de pesquisa, surgiram algumas definições importantes do que seria um agente, como a inicialmente proposta por Wooldridge (1997WOOLDRIDGE, M. J. Agent-based software engineering. IEE Proceedings on Soft- ware Engineering, v.144, n.1, p.26-37, 1997. apud Jennings, 1999JENNINGS, N. R. Agent-oriented software engineering. In: GARIJO, F. J.; BOMAN, M. (Ed.) Multiagent System Engineering, 9th European Workshop on Modelling Autonomous Agents in a Multi-Agent World, MAAMAW ’99. Valencia, Spain, June 30 - July 2, 1999, Proceedings, v.1647 of Lecture Notes in Computer Science, p.1-7., p.1): “Um agente é um sistema computacional encapsulado que está situado em algum ambiente, e que é capaz de ação autônoma e flexível naquele ambiente, a fim de cumprir seus objetivos”.\\n\\nA inserção da dimensão organizacional e a interação com os usuários foi proposta na sequência em Boissier e Sichman (2004BOISSIER, O.; SICHMAN, J. Organization oriented programming. Tutorial Notes. In: 3rd. INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTI-AGENT SYSTEMS (AAMAS 2004), New York, USA, 2004., p.5): “Um agente é entidade real ou virtual, que é autônoma, pró-ativa, reativa e social, sendo capaz de exibir atividade organizada de modo a atingir seus objetivos, eventualmente interagindo com usuários”.\\n\\nEm ambas as definições, menciona-se o conceito de autonomia, crucial para que se possa refletir sobre os possíveis efeitos positivos e negativos da interação desses sistemas com os seres humanos.\\n\\nCostuma-se encontrar na literatura de IA várias definições para o termo autonomia. Quase todas são definições relacionais, associadas a pelo menos quatro significados muito diferentes, como inicialmente discutido em Sichman (1995SICHMAN, J. S. Du Raisonnement Social Chez les Agents: Une Approche Fondée sur la Théorie de la Dépendance. Grenoble, 1995. Thèse (Doctorat) - Institut National Polytechnique de Grenoble., p.50):\\n\\nMais recentemente, tal caráter plurifacetado de noção de autonomia foi reiterado em (Dignum, 2019DIGNUM, V. Responsible Artificial Intelligence - How to Develop and Use AI in a Responsible Way. Artificial Intelligence: Foundations, Theory, and Algorithms. Springer, 2019., p.18):\\n\\nCertamente, a definição de autonomia em relação às suas motivações é a que provoca mais discussões no contexto das atuais e (potencialmente) futuras aplicações de IA. Deve-se certamente discutir até que ponto se deseja que um dispositivo inteligente seja autônomo nesse sentido: talvez seja adequado aceitar a autonomia de um aspirador de pó robótico (afinal, não seria necessário informá-lo qual local deve ser limpo em primeiro lugar), mas talvez esse não fosse o caso de um agente inteligente de reserva de viagens (talvez fosse mais adequado que ele sugerisse opções mas não tomasse a iniciativa de comprá-las antes de uma confirmação do usuário).\\n\\nUm trabalho muito interessante que propõe uma discussão nesse sentido é o proposto em Falcone e Castelfranchi (2000FALCONE, R.; CASTELFRANCHI, C. Grounding autonomy adjustment on delegation and trust theory. Journal of Experimental & Theoretical Artificial Intelligence, v.12, n.2, p.149-51, 2000.), onde se discutem graus de autonomia distintos que podem ser outorgados a esses agentes artificiais, fundeados em métricas de confiança baseadas no histórico de interações anteriores. Similarmente ao que ocorre na sociedade humana, talvez numa primeira interação entre um docente e seu orientado, o primeiro explique muito mais detalhadamente os procedimentos experimentais que devem ser realizados; à medida que mais interações bem-sucedidas ocorram, no futuro provavelmente pode ocorrer que o docente delegue certa autonomia de planejamento ao seu orientado. Um exemplo de autonomia de planejamento, no contexto de interações entre agentes inteligentes autônomos, pode ser visto em Maia e Sichman (2020MAIA, A. V.; SICHMAN, J. S. Representing planning autonomy in agent organizational models. Theoretical Computer Science, v.805, p.92-108, 2020.).\\n\\nNo caso particular de interações entre tais agentes inteligentes e humanos, um grande desafio é incorporar tais graus de autonomia nos chamados sistemas sociotécnicos.\\n\\nAntes de analisarmos os avanços e riscos potenciais da IA per se, cabe introduzir o conceito de Sistemas Sociotécnicos (SST). O termo foi cunhado por Eric Trist, Ken Bamforth e Fred Emery, na era da Segunda Guerra Mundial, derivado de seu estudo com trabalhadores em minas de carvão inglesas no Instituto Tavistock em Londres (Trist et al., 2013).\\n\\nA abordagem, segundo Appelbaum (1997APPELBAUM, S. H. Socio-technical systems theory: an intervention strategy for organizational development. Management Decision, v.35, n.6, 1997.), parte da premissa de que organizações são compostas de elementos sociais e técnicos, que trabalham conjuntamente para realizar as tarefas organizacionais. Tal atuação conjunta gera tanto produtos físicos como resultados sociais/psicológicos. O foco da abordagem consiste em possibilitar que os dois elementos gerem resultados positivos, diferentemente dos métodos convencionais em que as pessoas se adaptem e se ajustem aos elementos técnicos.\\n\\nTais sistemas já estão presentes em nossas vidas há pelo menos duas décadas: basta pensar nas nossas experiências com diversos tipos de call-center ou serviços bancários. Atualmente, na maioria dos casos, os elementos técnicos fornecem subsídios para que humanos possam tomar decisões. Há instâncias para recursos que podem, em certos casos, alterar decisões tomadas de forma equivocada, inclusive aplicando eventualmente sanções aos atores envolvidos para aprimorar os resultados futuros do sistema. Entretanto, a inserção da tecnologia de IA em tais sistemas pode alterar tal prática, fazendo que os próprios elementos técnicos possam tomar algumas decisões. Tal mudança de paradigma não é necessariamente boa ou ruim, mas tais sistemas necessitam incorporar outras propriedades inerentes à interação humana.\\n\\nEm seu trabalho seminal sobre IA Responsável, Virginia Dignum (2019DIGNUM, V. Responsible Artificial Intelligence - How to Develop and Use AI in a Responsible Way. Artificial Intelligence: Foundations, Theory, and Algorithms. Springer, 2019.) sintetiza num livro fascinante como deve-se desenvolver e utilizar IA de modo responsável. A autora advoga que uma postura ética deve ser adotada em três instâncias distintas:\\n\\nPara a primeira dimensão (ética no projeto), a autora propõe uma abordagem denominada ART of AI, que garante que os valores humanos e princípios éticos, suas prioridades e escolhas sejam explicitamente incluídos nos processos de design de forma transparente e sistemática. Tal abordagem é composta por três partes:\\n\\nQuanto à segunda dimensão (ética no comportamento), deve-se levar em conta que as sociedades humanas usualmente seguem normas para facilitar a interação. Tais normas, em muitos casos, levam em conta valores morais para embasar decisões. Assim, um grande desafio é incorporar tais normas e valores em sistemas de IA. Tal assunto vem sendo tratado pelos pesquisadores da área há mais de vinte anos, por exemplo na série de workshops denominada Coordination, Organization, Institutions and Norms in agent systems (Coin, 2005). Trata-se de embasar tais agentes autônomos com mecanismos de decisão que possam ser também baseados em sentimentos e valores morais, como proposto em Bazzan et al. (2002BAZZAN, A. L. et al. Evolution of agents with moral sentiments in an iterated prisoner’s dilemma exercise. In: Game theory and decision theory in agent-based systems. Springer. 2002. p.43-64.), ou que possam julgar a dimensão ética de seu próprio comportamento e dos comportamentos de outros agentes, como apresentado em Cointe et al. (2016COINTE, N. et al. Ethical judgment of agents’ behaviors in multi-agent systems. In: JONKER, C. M. et al. (Ed.) Proceedings of the 2016 International Conference on Autonomous Agents & Multiagent Systems. Singapore, May 9-13, 2016, p.1106-14. ACM.). Além dessa perspectiva individual, necessita-se também prover mecanismos de governança adequados, que possam eventualmente sancionar comportamentos distintos dos esperados por estes agentes, como proposto em Nardin et al. (2016NARDIN, L. G. et al. Classifying sanctions and designing a conceptual sanctioning process model for socio-technical systems. Knowledge Engineering Review, v.31, n.2, p.142-66, 2016.).\\n\\nA questão da transparência é uma condição necessária para tais agentes inteligentes possam argumentar e explicar as decisões por eles tomadas.\\n\\nIA explicável e IA para o bem\\n\\nOs chamados sistemas de IA explicáveis incorporam processos de explicação que permitem aos usuários obter informações sobre os modelos e decisões do sistema. O Explainable Artificial Intelligence workshop (XAI, 2018), evento satélite da ECAI/IJCAI 2018, ocorrida em Estocolmo, Suécia, possibilitou reunir pesquisadores interessados em IA, interação homem-computador, modelagem cognitiva e teorias cognitivas de explicação e transparência. Um tema fundamental, dado seu sucesso recente, foi como adicionar explicações a técnicas de aprendizado profundo, quase sempre baseados em modelos de caixa-preta, cujos parâmetros internos e seus respectivos valores são pouco entendidos pelo usuário.\\n\\nA preocupação com as finalidades de uso de sistemas de IA também têm sido objeto de debate nos últimos anos. O AI for Social Good workshop (AI4G 2019), evento satélite da IJCAI 2019, ocorrida em Macao, China, teve como objetivo explorar como a IA poderia contribuir para resolver problemas sociais.\\n\\nJá o Responsible Artificial Intelligence Agents workshop (Raia, 2019), evento satélite do AAMAS 2019, ocorrido em Montreal, Canadá, reuniu pesquisadores de IA, ética, filosofia, robótica, psicologia, antropologia, ciências cognitivas, direito, estudos de governança regulatória e engenharia para discutir e trabalhar sobre os complexos desafios relacionados ao projeto e à regulamentação de sistemas de IA. Concentrou-se em três aspectos que juntos podem garantir que a IA seja desenvolvida para o bem da sociedade (por exemplo, contribuindo para os objetivos de desenvolvimento sustentável da ONU), usando processos verificáveis e responsáveis, e que seu impacto seja governado por instituições e mecanismos justos e inclusivos.\\n\\nTais preocupações também têm norteado a criação de centros interdisciplinares para a formação de alunos na área. A UK Research and Innovation (UKRI) é uma agência de financiamento britânica que trabalha em parceria com universidades, organizações de pesquisa, empresas, instituições de caridade e governo para criar o melhor ambiente possível para a pesquisa e inovação florescerem. Em particular, apoiou recentemente a criação de 16 Centros de Treinamento de Doutorado (CDT) em Inteligência Artificial, visando formar 1.000 estudantes de doutorado para explorar o potencial da IA para transformar a maneira como trabalhamos e vivemos. As áreas de pesquisa são diversas, envolvendo desde saúde e mudanças climáticas a ética e música. Entre tais centros, podem-se destacar o Centre for Doctoral Training in Safe & Trusted AI (STAI, 2019), envolvendo o King’s College e o Imperial College, em Londres, e o Centre for Doctoral Training in Accountable, Responsible and Transparent AI (ART-AI, 2019), sediado na University of Bath.\\n\\nHá cinco anos, num artigo divulgado no Jornal da USP que foi escrito juntamente com meus colegas Fabio Cozman e Claudio Pinhanez, ambos hoje à frente do Centro de Inteligência Artificial da USP (C4AI), já apontávamos para os grandes avanços da IA nas últimas décadas (Sichman et al., 2016SICHMAN, J. S. et al. É possível a máquina superar o ser humano? Jornal da USP, n.XXX1, 2016.):\\n\\nNesse mesmo artigo, também mostramos que os temores a respeito de robôs aniquiladores da raça humana não poderiam ser construídos com a tecnologia atual:\\n\\nNum artigo interessante, Thomas Dietterich e Eric Horvitz (2015DIETTERICH, T. G.; HORVITZ, E. Rise of concerns about AI: reflections and directions. Communications of the ACM, v.58, n.10, p.38-40, 2015.) elencaram cinco classes de riscos envolvendo o uso de sistemas de IA:\\n\\nDentre estes riscos, os três últimos merecem maior atenção, por serem mais particulares ao uso da tecnologia de IA.\\n\\nSob qualquer perspectiva e métrica, é inegável que a IA alcançou um tremendo sucesso. As maiores empresas da economia mundial, como as Big Techs, são efetivamente empresas de IA. Como mencionado na introdução, tal sucesso se deu pelo barateamento dos custos de processamento e de memória, surgimento de novos paradigmas, como as redes neurais profundas e a enorme quantidade de dados disponível nas redes e mídias sociais.\\n\\nNovamente fazendo referência ao trabalho de Virginia Dignum (2019DIGNUM, V. Responsible Artificial Intelligence - How to Develop and Use AI in a Responsible Way. Artificial Intelligence: Foundations, Theory, and Algorithms. Springer, 2019.) sobre IA Responsável, a questão ética dos sistemas de IA que já fazem parte do nosso quotidiano deve ser ressaltado:\\n\\nO desenvolvimento e o uso da IA levantam questões éticas fundamentais para a sociedade, que são de vital importância para o nosso futuro. Já existe muito debate sobre o impacto da IA no trabalho, interações sociais (incluindo cuidados de saúde), privacidade, justiça e segurança (incluindo iniciativas de paz e guerra). O impacto social e ético da IA abrange muitos domínios, por exemplo, os sistemas de classificação de máquinas levantam questões sobre privacidade e preconceitos e veículos autônomos levantam questões sobre segurança e responsabilidade. Pesquisadores, decisores políticos, indústria e sociedade reconhecem a necessidade de abordagens que garantam as tecnologias de IA de uso seguro, benéfico e justo, para considerar as implicações da tomada de decisão ética e legalmente relevante pelas máquinas e o status ético e legal da IA. Essas abordagens incluem o desenvolvimento de métodos e ferramentas, atividades de consulta e treinamento e esforços de governança e regulamentação.\\n\\nPara encerrar, cabe relembrar uma frase do fundador da Cibernética, Norbert Wiener, que faz parte do artigo “Some Moral and Technical Consequences of Automation”, publicado na revista Science, em 1960: “Se usarmos, para atingir nossos objetivos, um órgão mecânico em cujo funcionamento não podemos interferir de forma eficaz ... é melhor estarmos bem certos de que o propósito colocado na máquina é aquele que realmente desejamos”.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mostrando o texto\n",
    "artigo.cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Realize a tokenização de palavras e setenças"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rafael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\rafael\\desktop\\projetos\\python\\ia\\.venv\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\rafael\\desktop\\projetos\\python\\ia\\.venv\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\rafael\\desktop\\projetos\\python\\ia\\.venv\\lib\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\rafael\\desktop\\projetos\\python\\ia\\.venv\\lib\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rafael\\desktop\\projetos\\python\\ia\\.venv\\lib\\site-packages (from nltk) (4.67.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rafael\\desktop\\projetos\\python\\ia\\.venv\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Rafael\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\Rafael/nltk_data', 'c:\\\\Users\\\\Rafael\\\\Desktop\\\\Projetos\\\\Python\\\\IA\\\\.venv\\\\nltk_data', 'c:\\\\Users\\\\Rafael\\\\Desktop\\\\Projetos\\\\Python\\\\IA\\\\.venv\\\\share\\\\nltk_data', 'c:\\\\Users\\\\Rafael\\\\Desktop\\\\Projetos\\\\Python\\\\IA\\\\.venv\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\Rafael\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data', 'C:\\\\Users\\\\Rafael/nltk_data']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.data.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.data.path.append('C:\\\\Users\\\\Rafael/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentencas_artigo = sent_tokenize(artigo.cleaned_text, language='portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentencas_artigo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palavras_artigo = word_tokenize(artigo.cleaned_text, language='portuguese')\n",
    "print(palavras_artigo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove pontuação da lista de palavras\n",
    "\n",
    "import string\n",
    "palavras_artigo_sem_pontuacao = [palavra for palavra in palavras_artigo if palavra.isalpha()]\n",
    "print(palavras_artigo_sem_pontuacao)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Realize a distribução de frequência das palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdisk_artigo = FreqDist(palavras_artigo)\n",
    "fdisk_artigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdisk_artigo_sem_pontuacao = FreqDist(palavras_artigo_sem_pontuacao)\n",
    "palavras_artigo_sem_pontuacao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdisk_artigo.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdisk_artigo_sem_pontuacao.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crie uma função plot_cloud para WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdisk_artigo.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdisk_artigo_sem_pontuacao.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cloud(word_frequencies, title):\n",
    "  wordcloud = WordCloud(width=2000, height=1000, background_color='white',random_state = 1, collocations=False).generate_from_frequencies(word_frequencies)\n",
    "  # Criar a Figura\n",
    "  plt.figure(figsize=(10, 5))\n",
    "\n",
    "  # Exibir a Word Cloud\n",
    "  plt.imshow(wordcloud, interpolation='bilinear')\n",
    "\n",
    "  # Remover Eixos\n",
    "  plt.axis('off')\n",
    "\n",
    "  # Adcicionar o titulo\n",
    "  plt.title(title)\n",
    "  plt.show()\n",
    "\n",
    "# Imprimindo na tela:\n",
    "plot_cloud(fdisk_artigo_sem_pontuacao, 'Nuvem de Palavras do Artigo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição da Função\n",
    "def plot_cloud2(wordcloud):\n",
    "    # Criar a Figura\n",
    "    plt.figure(figsize=(40, 30))\n",
    "\n",
    "    # Exibir a Word Cloud\n",
    "    plt.imshow(wordcloud)\n",
    "\n",
    "    # Remover Eixos\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_artigos = WordCloud(width = 3000, height = 2000, random_state = 1,\n",
    "background_color='black', colormap='Pastel1', collocations=False,\n",
    "stopwords=STOPWORDS).generate(artigo.cleaned_text)\n",
    "\n",
    "plot_cloud2(wordcloud_artigos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
